Image Captioning using Deep Learning


This project implements image captioning using deep learning techniques. It generates textual descriptions for images by combining computer vision and natural language processing (NLP). The model utilizes neural networks, specifically LSTM networks, to generate captions based on the visual features extracted from images.

Dataset:

The project uses the Flickr8k dataset, which consists of 8,000 images from Flickr, along with five captions for each image. You can download the dataset from Kaggle. Extract the dataset files and ensure they are accessible for the code.

Dataset link : https://www.kaggle.com/datasets/adityajn105/flickr8k

Install the dependencies using the following command:

pip install -r requirements.txt

Usage:

Ensure the dataset files are available in the correct directory.

Run the "Team1_code_gui.ipynb" script to generate captions for an image. upload the image to gui and the captions gets generated in the textbox of gui.



